{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install  google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import store_to_vdb\n",
    "\n",
    "# from apiclient.discovery import build\n",
    "# from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions = store_to_vdb.playlist_to_captions(\"PLUl4u3cNGP60uVBMaoNERc6knT_MgPKS0\")\n",
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following content is provided under a Creative Commons license.\n",
      "1034\n",
      "897\n",
      "1015\n",
      "843\n",
      "836\n",
      "810\n",
      "1065\n",
      "793\n",
      "723\n",
      "913\n",
      "975\n",
      "673\n",
      "729\n",
      "687\n",
      "864\n",
      "677\n",
      "748\n",
      "774\n",
      "797\n",
      "700\n",
      "918\n",
      "579\n"
     ]
    }
   ],
   "source": [
    "captions = store_to_vdb.captions_processing(captions)\n",
    "print(captions[0]['video_captions'][0]['text'])\n",
    "for i in range(len(captions)):\n",
    "    print(len(captions[i]['video_captions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810\n"
     ]
    }
   ],
   "source": [
    "print(len(captions[5]['video_captions']))\n",
    "embeds_test = store_to_vdb.captions_to_embeddings([captions[5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import cohere\n",
    "\n",
    "\n",
    "# def captions_to_embeddings(videos_captions):\n",
    "#     api_key = 'SrLBFEol9tRK7n7LY9FRRcHuN9QT5MLIzLmBSziT'\n",
    "#     # Create and retrieve a Cohere API key from os.cohere.ai\n",
    "#     co = cohere.Client(api_key)\n",
    "#     all_embeds = []\n",
    "#     no_texts = 0\n",
    "#     for captions in videos_captions :\n",
    "#         embeds = []\n",
    "#         texts = []\n",
    "#         for caption in captions['video_captions'] :\n",
    "#             dic = {}\n",
    "#             dic['start'] = caption['start']\n",
    "#             dic['video_id'] = captions['video_id']\n",
    "#             texts.append(caption['text'])\n",
    "#             dic['embedding'] = []  \n",
    "#             embeds.append(dic)\n",
    "#         if(len(texts) > 1600):\n",
    "#             #call on video captions embedding\n",
    "# #             video_embeddings = \n",
    "#             pass\n",
    "#         else:\n",
    "#             if((no_texts+len(texts)) > 1600 ):\n",
    "#                 no_texts = 0 \n",
    "#                 print(\"sleep\")\n",
    "#                 time.sleep(60)\n",
    "#             no_texts += len(texts)\n",
    "#             video_embeddings = co.embed(texts,model=\"small\").embeddings\n",
    "#             print(len(texts))\n",
    "        \n",
    "#         for i in range(len(embeds)):\n",
    "#             embeds[i]['embedding'] =  video_embeddings[i]\n",
    "        \n",
    "#         all_embeds.append(embeds)\n",
    "          \n",
    "#     return all_embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emds = store_to_vdb.captions_to_embeddings(captions[16:])\n",
    "len(emds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pinecone\n",
    "PIENCONE_API_KEY = \"3d2006de-95b3-4e7d-9ec1-54133c34001e\"\n",
    "pinecone.init(PIENCONE_API_KEY, environment='us-west1-gcp')\n",
    "index_name = 'first-index'\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "last_id =  index.describe_index_stats()['total_vector_count']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21681"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pinecone\n",
    "# import cohere\n",
    "# co = cohere.Client(\"SrLBFEol9tRK7n7LY9FRRcHuN9QT5MLIzLmBSziT\")\n",
    "\n",
    "# query = \"hello world\"\n",
    "\n",
    "# index = pinecone.Index(\"first-index\")\n",
    "# # create the query embedding\n",
    "# xq = co.embed(\n",
    "#     texts=[query],\n",
    "#     model='small',\n",
    "#     truncate='LEFT'\n",
    "# ).embeddings[0]\n",
    "\n",
    "# example = [[ {\"start\":6 , \"video_id\":\"C1lhuz6pZC0\" , \"embedding\":xq,\"text\": query } ]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Piencone_indexing(collection):    #    -> [[{}]]  -> [[ {start:--- , video_id:--- , embedding:--- }   ,]]\n",
    "    \n",
    "    PIENCONE_API_KEY = \"3d2006de-95b3-4e7d-9ec1-54133c34001e\"\n",
    "    \n",
    "    pinecone.init(PIENCONE_API_KEY, environment='us-west1-gcp')\n",
    "    index_name = 'first-index'\n",
    "    print('============1===============')\n",
    "    \n",
    "    shape = np.array(collection[0][0][\"embedding\"]).shape       # (1024,)\n",
    "\n",
    "    # if the index does not exist, we create it\n",
    "    if index_name not in pinecone.list_indexes():\n",
    "        pinecone.create_index(\n",
    "            index_name,\n",
    "            dimension=shape[0],\n",
    "            metric='dotproduct'\n",
    "        )\n",
    "    # connect to index\n",
    "    index = pinecone.Index(index_name)\n",
    "    print('============2===============')\n",
    "    \n",
    "    last_id =  index.describe_index_stats()['total_vector_count']+1\n",
    "    for x in range(len(collection)):\n",
    "        list_dic_data = collection[x]\n",
    "        print(len(collection[x]))\n",
    "        num_embeds = len(list_dic_data)\n",
    "        print(shape)\n",
    "\n",
    "        batch_size = 128\n",
    "\n",
    "        ids = [str(i) for i in range( last_id , last_id+ num_embeds + 1)]\n",
    "        last_id = last_id + num_embeds + 1\n",
    "        # create list of metadata dictionaries\n",
    "        embeds = []\n",
    "        meta_data = []\n",
    "        \n",
    "        for dic_data in list_dic_data:\n",
    "            \n",
    "            meta = {}\n",
    "            for key in dic_data.keys():\n",
    "                if key == 'embedding':\n",
    "                    embeds.append(dic_data[key])\n",
    "                else:\n",
    "                    meta[key] = dic_data[key]\n",
    "            meta_data.append(meta)\n",
    "\n",
    "        print(meta_data[0][\"video_id\"] , \" \",len(meta_data))\n",
    "\n",
    "\n",
    "        # create list of (id, vector, metadata) tuples to be upserted\n",
    "        to_upsert = list(zip(ids, embeds, meta_data))\n",
    "#         to_upsert = list(zip(ids, embeds))\n",
    "        for i in range(0, shape[0]+1, batch_size):\n",
    "            i_end = min(i+batch_size, shape[0])\n",
    "            a = to_upsert[i:i_end]\n",
    "            if(len(a) == 0):\n",
    "                print(\"empty\")\n",
    "                break\n",
    "\n",
    "            index.upsert(vectors=a)\n",
    "\n",
    "        # let's view the index statistics\n",
    "        print(index.describe_index_stats())\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============1===============\n",
      "============2===============\n",
      "748\n",
      "(1024,)\n",
      "WW3ZJHPwvyg   748\n",
      "empty\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 22349}},\n",
      " 'total_vector_count': 22349}\n",
      "774\n",
      "(1024,)\n",
      "a1ZCeFpeW0o   774\n",
      "empty\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 23123}},\n",
      " 'total_vector_count': 23123}\n",
      "797\n",
      "(1024,)\n",
      "X-ix97pw0xY   797\n",
      "empty\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 23920}},\n",
      " 'total_vector_count': 23920}\n",
      "700\n",
      "(1024,)\n",
      "mc1y8m9-hOM   700\n",
      "empty\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 24620}},\n",
      " 'total_vector_count': 24620}\n",
      "918\n",
      "(1024,)\n",
      "OYcdw5vOgIc   918\n",
      "empty\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 25538}},\n",
      " 'total_vector_count': 25538}\n",
      "579\n",
      "(1024,)\n",
      "lWW54ts9Ubo   579\n",
      "empty\n",
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 26117}},\n",
      " 'total_vector_count': 26117}\n"
     ]
    }
   ],
   "source": [
    "Piencone_indexing(emds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.Client(\"SrLBFEol9tRK7n7LY9FRRcHuN9QT5MLIzLmBSziT\")\n",
    "\n",
    "query = \"population bias\"\n",
    "\n",
    "index = pinecone.Index(\"first-index\")\n",
    "# create the query embedding\n",
    "xq = co.embed(\n",
    "    texts=[query],\n",
    "    model='small',\n",
    "    truncate='LEFT'\n",
    ").embeddings\n",
    "\n",
    "print(np.array(xq).shape)\n",
    "\n",
    "# query, returning the top 5 most similar results\n",
    "res = index.query(xq, top_k=5, include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '20316',\n",
       "              'metadata': {'start': 509.33,\n",
       "                           'text': 'Maybe this population is not the '\n",
       "                                   'population in the world.',\n",
       "                           'video_id': 'bFZ-0FH5hfs'},\n",
       "              'score': 1403.53088,\n",
       "              'sparseValues': {},\n",
       "              'values': []},\n",
       "             {'id': '7152',\n",
       "              'metadata': {'start': 2002.77,\n",
       "                           'text': 'It is true from the Census Bureau data.',\n",
       "                           'video_id': 'K2SC-WPdT6k'},\n",
       "              'score': 1306.06445,\n",
       "              'sparseValues': {},\n",
       "              'values': []},\n",
       "             {'id': '8652',\n",
       "              'metadata': {'start': 4103.84,\n",
       "                           'text': 'Here what I am assuming is that my '\n",
       "                                   'population is homogeneous.',\n",
       "                           'video_id': 'VPZD_aij8H0'},\n",
       "              'score': 1287.48157,\n",
       "              'sparseValues': {},\n",
       "              'values': []},\n",
       "             {'id': '16278',\n",
       "              'metadata': {'start': 257.62,\n",
       "                           'text': 'And so here of course, the population is '\n",
       "                                   'not uniformly distributed according to '\n",
       "                                   'racial group.',\n",
       "                           'video_id': 'a66tfLdr6oY'},\n",
       "              'score': 1262.81775,\n",
       "              'sparseValues': {},\n",
       "              'values': []},\n",
       "             {'id': '3695',\n",
       "              'metadata': {'start': 2038.41,\n",
       "                           'text': 'One is, does the distribution of the '\n",
       "                                   'population matter?',\n",
       "                           'video_id': 'soZv_KKax3E'},\n",
       "              'score': 1245.9679,\n",
       "              'sparseValues': {},\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captions_to_embeddings(videos_captions):\n",
    "    api_key = 'SrLBFEol9tRK7n7LY9FRRcHuN9QT5MLIzLmBSziT'\n",
    "    # Create and retrieve a Cohere API key from os.cohere.ai\n",
    "    co = cohere.Client(api_key)\n",
    "    all_embeds = []\n",
    "    for captions in videos_captions :\n",
    "        embeds = []\n",
    "        texts = []\n",
    "        video_embeddings = []\n",
    "        caps = captions['video_captions']\n",
    "        for i in range(len(caps)):\n",
    "            texts.append(caps[i]['text'])\n",
    "            dic['start'] = caps[i]['start']\n",
    "            dic['video_id'] = caps[i]['video_id']\n",
    "            embeds.append(dic)\n",
    "            if((i+1)%16 == 0):\n",
    "                video_embeddings + = co.embed(texts,truncate='RIGHT'model=\"small\").embeddings\n",
    "                text = []\n",
    "        if(len(texts) > 0):\n",
    "            video_embeddings + = co.embed(texts,truncate='RIGHT'model=\"small\").embeddings\n",
    "            \n",
    "        for i in range(len(embeds)):\n",
    "            embeds[i]['embedding'] =  video_embeddings[i]\n",
    "        all_embeds.append(embeds)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
